{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "121c1e43-adeb-405e-85b3-7ad30b804730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, BertTokenizerFast\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.functional import cross_entropy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0faea181-c1ad-4afa-b60e-61b366925729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3537ba44-83a7-4830-84b6-dfffdc2e681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/home/kunal/Dev/RedditBot/identifying-depression/train.csv\",lineterminator='\\n')\n",
    "test = pd.read_csv(\"/home/kunal/Dev/RedditBot/identifying-depression/test.csv\",lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd5e49f8-91cb-4e87-b060-bb242626b108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149293</td>\n",
       "      <td>never thought id be one of those people  who i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31658</td>\n",
       "      <td>hes a racist redneck farmer judging by his fac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119474</td>\n",
       "      <td>dmt no im not joking</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>223606</td>\n",
       "      <td>upliftingnews  leave us to our commiserating</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219628</td>\n",
       "      <td>and spend your days in bed hoping for some kin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143707</th>\n",
       "      <td>11612</td>\n",
       "      <td>i havent seen my therapist in about  or  month...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143708</th>\n",
       "      <td>81389</td>\n",
       "      <td>ive been there for a couple weeks at a time bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143709</th>\n",
       "      <td>159541</td>\n",
       "      <td>the oldest is the trailblazer with restriction...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143710</th>\n",
       "      <td>49251</td>\n",
       "      <td>hey thanks for writing this out  ive seen some...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143711</th>\n",
       "      <td>16082</td>\n",
       "      <td>i teared up   youre right even us muggles are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143712 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  label\n",
       "0           149293  never thought id be one of those people  who i...      0\n",
       "1            31658  hes a racist redneck farmer judging by his fac...      0\n",
       "2           119474                               dmt no im not joking      0\n",
       "3           223606       upliftingnews  leave us to our commiserating      1\n",
       "4           219628  and spend your days in bed hoping for some kin...      1\n",
       "...            ...                                                ...    ...\n",
       "143707       11612  i havent seen my therapist in about  or  month...      1\n",
       "143708       81389  ive been there for a couple weeks at a time bu...      1\n",
       "143709      159541  the oldest is the trailblazer with restriction...      0\n",
       "143710       49251  hey thanks for writing this out  ive seen some...      1\n",
       "143711       16082  i teared up   youre right even us muggles are ...      1\n",
       "\n",
       "[143712 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3154507-02af-45da-9dff-c4010cdb6842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233746</td>\n",
       "      <td>tommy vercetti for me</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83283</td>\n",
       "      <td>youre amazing way to go i recently lost my job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172981</td>\n",
       "      <td>happy birthday keep on living it can get better</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144431</td>\n",
       "      <td>painting pft</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>233840</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47900</th>\n",
       "      <td>179962</td>\n",
       "      <td>you said it perfectly i stay up late to be pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47901</th>\n",
       "      <td>81929</td>\n",
       "      <td>cant remember whats its called but the japanes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47902</th>\n",
       "      <td>172708</td>\n",
       "      <td>lets take  for instance  think of it like  poi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47903</th>\n",
       "      <td>215792</td>\n",
       "      <td>i broke down completely twice last night and n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47904</th>\n",
       "      <td>104809</td>\n",
       "      <td>well at least hes not a faggy goth kid p</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47905 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  label\n",
       "0          233746                              tommy vercetti for me      0\n",
       "1           83283  youre amazing way to go i recently lost my job...      1\n",
       "2          172981    happy birthday keep on living it can get better      1\n",
       "3          144431                                       painting pft      0\n",
       "4          233840                                               same      1\n",
       "...           ...                                                ...    ...\n",
       "47900      179962  you said it perfectly i stay up late to be pro...      1\n",
       "47901       81929  cant remember whats its called but the japanes...      0\n",
       "47902      172708  lets take  for instance  think of it like  poi...      0\n",
       "47903      215792  i broke down completely twice last night and n...      1\n",
       "47904      104809           well at least hes not a faggy goth kid p      1\n",
       "\n",
       "[47905 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fd1bd98-1ee8-40e6-b6ec-5d4d4b885f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21486/3636092027.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = train.append(test)\n"
     ]
    }
   ],
   "source": [
    "df = train.append(test)\n",
    "df = df.dropna()\n",
    "# df\n",
    "df = df[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c4ab181-c68b-467c-aa18-4e71656c7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
    "                                                                    random_state = 2021, \n",
    "                                                                    test_size = 0.3, \n",
    "                                                                    stratify = df['label'])\n",
    "  \n",
    "  \n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state = 2021, \n",
    "                                                                test_size = 0.5, \n",
    "                                                                stratify = temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42daff6f-f815-4a5a-8ac0-cf238634c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_len = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae9cdd6-a4c4-497e-87a7-60c6f7942790",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    padding=True,\n",
    "    max_length = pad_len,\n",
    "    truncation = True)\n",
    "  \n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = pad_len,\n",
    "    padding= True,\n",
    "    truncation = True)\n",
    "  \n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = pad_len,\n",
    "    padding = True,\n",
    "    truncation = True\n",
    ")\n",
    "  \n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "  \n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "  \n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ad02d6-846a-4ab4-9a95-c6363b174de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze the pretrained layers\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "  \n",
    "#defining new layers\n",
    "class BERT_architecture(nn.Module):\n",
    "  \n",
    "    def __init__(self, bert):\n",
    "        \n",
    "      super(BERT_architecture, self).__init__()\n",
    "  \n",
    "      self.bert = bert \n",
    "        \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "  \n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "        \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,2)\n",
    "  \n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "  \n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "  \n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "        \n",
    "      x = self.fc1(cls_hs)\n",
    "  \n",
    "      x = self.relu(x)\n",
    "  \n",
    "      x = self.dropout(x)\n",
    "  \n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "        \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "  \n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21a91ba6-8d3e-4294-b241-a28c5999ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT_architecture(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba664af0-7c3c-4835-b87d-f69b28b8d443",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),lr = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18c7690b-bc9c-49c1-aac3-4884878242ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    model.train()\n",
    "  \n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "  # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "    \n",
    "  # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "      \n",
    "    # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "              print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "  \n",
    "    # push the batch to gpu\n",
    "    \n",
    "        batch = [r.to(device) for r in batch]\n",
    "   \n",
    "        sent_id, mask, labels = batch\n",
    "  \n",
    "    # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "  \n",
    "    # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "  \n",
    "    # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "  \n",
    "    # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "  \n",
    "    # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "  \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "  \n",
    "    # update parameters\n",
    "        optimizer.step()\n",
    "  \n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "  \n",
    "    # append the model predictions\n",
    "        total_preds.append(preds)\n",
    "  \n",
    "  # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "  \n",
    "  #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "459da0da-e0fa-4cae-bf26-ab147d1dd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate():\n",
    "    \n",
    "  print(\"\\nEvaluating...\")\n",
    "    \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "  \n",
    "  total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "      \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "        \n",
    "      # # Calculate elapsed time in minutes.\n",
    "      # elapsed = format_time(time.time() - t0)\n",
    "              \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "  \n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "  \n",
    "    sent_id, mask, labels = batch\n",
    "  \n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "        \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "  \n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "  \n",
    "      total_loss = total_loss + loss.item()\n",
    "  \n",
    "      preds = preds.detach().cpu().numpy()\n",
    "  \n",
    "      total_preds.append(preds)\n",
    "  \n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "  \n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "  \n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7a99417-96f9-46bc-86d9-6989dd4fd424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a738794-2cf3-4305-a90c-0caa779b9635",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c03e2a8-d3c7-4279-ac7f-9b830df2befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "train_dataloader = DataLoader(list(zip(train_seq,train_mask, train_y)), shuffle=True, batch_size=16)\n",
    "val_dataloader = DataLoader(list(zip(val_seq,val_mask, val_y)), shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9da89b8f-f3a0-4a39-8510-55f6bf6bc02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    50  of    438.\n",
      "  Batch   100  of    438.\n",
      "  Batch   150  of    438.\n",
      "  Batch   200  of    438.\n",
      "  Batch   250  of    438.\n",
      "  Batch   300  of    438.\n",
      "  Batch   350  of    438.\n",
      "  Batch   400  of    438.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6402020277497975,\n",
       " array([[-0.71609676, -0.6707124 ],\n",
       "        [-0.63132036, -0.75905   ],\n",
       "        [-0.63079804, -0.7596438 ],\n",
       "        ...,\n",
       "        [-0.11821792, -2.193752  ],\n",
       "        [-0.21066636, -1.6609645 ],\n",
       "        [-0.28877592, -1.3830199 ]], dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f55685b-9df3-4377-b969-af5c41ecc469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "  Batch    50  of     94.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.564265583106812,\n",
       " array([[-0.38390705, -1.1431748 ],\n",
       "        [-0.41954044, -1.0710424 ],\n",
       "        [-0.55595064, -0.8522057 ],\n",
       "        ...,\n",
       "        [-0.12021544, -2.1779752 ],\n",
       "        [-1.3220327 , -0.3100542 ],\n",
       "        [-1.4714636 , -0.2608314 ]], dtype=float32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "543d757a-3b8a-489c-9dbf-0252eb804acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       806\n",
      "           1       0.72      0.69      0.70       694\n",
      "\n",
      "    accuracy                           0.73      1500\n",
      "   macro avg       0.73      0.73      0.73      1500\n",
      "weighted avg       0.73      0.73      0.73      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    # print(preds.__dict__)\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "pred = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04a8d261-c3aa-451b-9994-f2a1a6a0846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4f28205-c6cf-4709-9598-46cd9f692a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7e3d4e4-5162-4c6e-8e36-186c2fde706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I wanna kill myself\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6b664f4-424d-4a3f-8e84-8e57c6b304c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 10587, 3102, 2870, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode_plus(\n",
    "    text,\n",
    "    padding=True,\n",
    "    max_length = pad_len,\n",
    "    truncation = True)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88e18b9b-2830-4ca2-9b2d-3598a04729af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_seq = torch.tensor(tokens['input_ids']).unsqueeze(0)\n",
    "tokens_mask = torch.tensor(tokens['attention_mask']).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baf605a5-9d6f-41c1-b347-9ce50bb5cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.forward(tokens_seq.to(device), tokens_mask.to(device))\n",
    "preds = preds.detach().cpu().numpy()\n",
    "\n",
    "pred = np.argmax(preds, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f3d7033-71ac-4f4f-99d5-69b040f70f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab4c93d7-0e76-4537-a43d-44b6b77fc354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.43546766, -1.0411797 ], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a1e1add7-e5ff-4725-90b2-bceab3e0a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pt\")\n",
    "# torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "905b1ec0-d3ad-4523-ae4b-3638d30c924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38400ba-12bc-4f92-b49d-b47713290dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
